const fs = require('fs');
const path = require('path');
const { Canvas, Image, ImageData, loadImage } = require('canvas');
const faceapi = require('face-api.js');
const axios = require('axios');

const cacheDir = path.join(__dirname, 'cache');
if (!fs.existsSync(cacheDir)) {
  fs.mkdirSync(cacheDir);
}

faceapi.env.monkeyPatch({ Canvas, Image, ImageData });

module.exports = {
  name: "age",
  dev: "HNT",
  info: "ƒêo√°n tu·ªïi v√† c·∫£m x√∫c c·ªßa ng∆∞·ªùi trong ·∫£nh, ƒë√°nh gi√° ƒë·ªô ƒë·∫πp trai or ƒë·∫πp g√°i.",
  usages: "[reply ·∫£nh]",
  onPrefix: true,
  cooldowns: 5,

  onLaunch: async function({ api, event }) {
    const { threadID, messageID, messageReply } = event;

    if (!messageReply || !messageReply.attachments || messageReply.attachments.length === 0) {
      return api.sendMessage("Vui l√≤ng reply m·ªôt ·∫£nh ƒë·ªÉ bot ƒëo√°n tu·ªïi.", threadID, messageID);
    }

    const attachment = messageReply.attachments[0];
    if (attachment.type === 'video' || attachment.type === 'animated_image') {
      return api.sendMessage("Bot kh√¥ng h·ªó tr·ª£ ph√¢n t√≠ch video ho·∫∑c GIF. Vui l√≤ng g·ª≠i ·∫£nh.", threadID, messageID);
    }

    try {
      const waitMessage = await api.sendMessage("ƒê·ª£i x√≠u ƒë·ªÉ bot ki·ªÉm tra ·∫£nh... ü§î", threadID);

      await faceapi.nets.ssdMobilenetv1.loadFromDisk('./commands/cache/models');
      await faceapi.nets.faceLandmark68Net.loadFromDisk('./commands/cache/models');
      await faceapi.nets.faceRecognitionNet.loadFromDisk('./commands/cache/models');
      await faceapi.nets.ageGenderNet.loadFromDisk('./commands/cache/models');
      await faceapi.nets.faceExpressionNet.loadFromDisk('./commands/cache/models'); // M√¥ h√¨nh c·∫£m x√∫c

      const imageUrl = attachment.url;
      const imageFileName = `image_${Date.now()}.jpg`;
      const imagePath = path.join(cacheDir, imageFileName);

      const response = await axios({
        url: imageUrl,
        responseType: 'stream',
      });

      await new Promise((resolve, reject) => {
        response.data.pipe(fs.createWriteStream(imagePath))
          .on('finish', resolve)
          .on('error', reject);
      });

      const imgBuffer = fs.readFileSync(imagePath);
      const image = await loadImage(imgBuffer);

      const detections = await faceapi.detectAllFaces(image).withAgeAndGender().withFaceExpressions(); // Th√™m c·∫£m x√∫c

      if (detections.length === 0) {
        fs.unlinkSync(imagePath);
        return api.sendMessage("Bot kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t n√†o trong ·∫£nh. Vui l√≤ng g·ª≠i ·∫£nh kh√°c.", threadID, messageID);
      }

      let maleCount = 0;
      let femaleCount = 0;
      let totalAge = 0;
      let responses = [];

      detections.forEach(detection => {
        const age = Math.round(detection.age);
        totalAge += age;
        const gender = detection.gender;
        
        if (gender === 'male') {
          maleCount++;
        } else {
          femaleCount++;
        }

        let personXungHo = '';
        if (age <= 12) {
          personXungHo = gender === 'male' ? 'c·∫≠u b√©' : 'em g√°i';
        } else if (age <= 18) {
          personXungHo = gender === 'male' ? 'b·∫°n tr·∫ª trai' : 'b·∫°n tr·∫ª g√°i';
        } else if (age <= 30) {
          personXungHo = gender === 'male' ? 'anh ch√†ng n√†y' : 'c√¥ g√°i n√†y';
        } else if (age <= 50) {
          personXungHo = gender === 'male' ? 'qu√Ω √¥ng n√†y' : 'qu√Ω b√† n√†y';
        } else {
          personXungHo = gender === 'male' ? 'ng∆∞·ªùi ƒë√†n √¥ng n√†y' : 'ng∆∞·ªùi ph·ª• n·ªØ n√†y';
        }

        responses.push(`${personXungHo} kho·∫£ng ${age} tu·ªïi.`);
      });

      const averageAge = Math.round(totalAge / detections.length);
      let xungHo = '';

      if (averageAge <= 12) {
        xungHo = 'em g√°i/ c·∫≠u b√©';
      } else if (averageAge <= 18) {
        xungHo = 'tr√°i nh·ªè/ b·∫°n tr·∫ª';
      } else if (averageAge <= 30) {
        xungHo = maleCount > femaleCount ? 'anh ch√†ng n√†y' : 'c√¥ g√°i n√†y';
      } else if (averageAge <= 50) {
        xungHo = maleCount > femaleCount ? 'qu√Ω √¥ng n√†y' : 'qu√Ω b√† n√†y';
      } else {
        xungHo = maleCount > femaleCount ? 'ng∆∞·ªùi ƒë√†n √¥ng n√†y' : 'ng∆∞·ªùi ph·ª• n·ªØ n√†y';
      }

      const beautyRating = Math.random(); 
      let beautyMessage = '';
      if (beautyRating > 0.8) {
        beautyMessage = `R·∫•t phong ƒë·ªô! üòç`;
      } else if (beautyRating > 0.6) {
        beautyMessage = `Kh√° thu h√∫t! üòÅ`;
      } else if (beautyRating > 0.4) {
        beautyMessage = `D·ªÖ th∆∞∆°ng! üòä`;
      } else {
        beautyMessage = `V·∫´n r·∫•t d·ªÖ m·∫øn! üòú`;
      }

      const emotions = detections[0].expressions;
      const maxEmotion = Object.keys(emotions).reduce((max, emotion) => emotions[emotion] > emotions[max] ? emotion : max, 'neutral');

      let emotionMessage = '';
      switch(maxEmotion) {
        case 'happy':
          emotionMessage = "Ng∆∞·ªùi n√†y c√≥ v·∫ª r·∫•t vui v·∫ª! üòä";
          break;
        case 'sad':
          emotionMessage = "Ng∆∞·ªùi n√†y tr√¥ng h∆°i bu·ªìn... üòî";
          break;
        case 'angry':
          emotionMessage = "Ng∆∞·ªùi n√†y c√≥ v·∫ª h∆°i t·ª©c gi·∫≠n... üò°";
          break;
        case 'surprised':
          emotionMessage = "Ng∆∞·ªùi n√†y ƒëang ng·∫°c nhi√™n! üò≤";
          break;
        default:
          emotionMessage = "Tr√¥ng ng∆∞·ªùi n√†y kh√° ƒëi·ªÅm tƒ©nh v√† trung l·∫≠p. üòå";
      }

      api.sendMessage(
        `Bot ƒë√£ ph√°t hi·ªán ${detections.length} khu√¥n m·∫∑t trong ·∫£nh. Hmm...${responses.join('\n')}\n${beautyMessage}\n${emotionMessage}`,
        threadID,
        () => {
          setTimeout(() => {
            api.unsendMessage(waitMessage.messageID);
          }, 3000);
          fs.unlinkSync(imagePath);
        },
        messageID
      );      
    } catch (error) {
      console.error("L·ªói khi ph√¢n t√≠ch khu√¥n m·∫∑t:", error);
      api.sendMessage("ƒê√£ x·∫£y ra l·ªói khi ph√¢n t√≠ch ·∫£nh. Vui l√≤ng th·ª≠ l·∫°i sau.", threadID, messageID);
    }
  }
};
